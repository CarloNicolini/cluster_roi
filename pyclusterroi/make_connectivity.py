#### make_connectivity.py
# Copyright (C) 2010 R. Cameron Craddock (cameron.craddock@gmail.com)
#
# This script is a part of the pyClusterROI python toolbox for the spatially
# constrained clustering of fMRI data. It constructs a spatially constrained
# connectivity matrix from a fMRI dataset, where then connectivity weight
# between two neighboring voxels is determined by the correlation between their
# BOLD time courses (tcorr), the correlation between functional connectivity
# maps generated by correlating the voxel time courses with every other voxel
# time course in the brain (scorr), or is 1 if the voxels are both in the brain
# and are neighbors.
#
# For more information refer to:
#
# Craddock, R. C.; James, G. A.; Holtzheimer, P. E.; Hu, X. P. & Mayberg, H. S.
# A whole brain fMRI atlas generated via spatially constrained spectral
# clustering Human Brain Mapping, 2012, 33, 1914-1928 doi: 10.1002/hbm.21333.
#
# ARTICLE{Craddock2012,
#   author = {Craddock, R C and James, G A and Holtzheimer, P E and Hu, X P and
#   Mayberg, H S},
#   title = {{A whole brain fMRI atlas generated via spatially constrained
#   spectral clustering}},
#   journal = {Human Brain Mapping},
#   year = {2012},
#   volume = {33},
#   pages = {1914--1928},
#   number = {8},
#   address = {Department of Neuroscience, Baylor College of Medicine, Houston,
#       TX, United States},
#   pmid = {21769991},
# }
#
# Documentation, updated source code and other information can be found at the
# NITRC web page: http://www.nitrc.org/projects/cluster_roi/ and on github at
# https://github.com/ccraddock/cluster_roi
#
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
####

# this scripts requires NumPy (numpy.scipy.org) to be installed in a directory
# that is accessible through PythonPath
import numpy as np


def get_neighbors(ix,msz):

    """
    array to find the indices of the voxels in a 3D cube centered at ix

    :param ix: center of the cube, single number NOT a list
    :param msz: dimensions of the full space
    :return: list of 1d indices for the voxels of the cube
    """

    if np.ndim(ix) > 0:
        raise TabError("ix should be a single integer, not a list")

    # array to add to 3d coordinates of seed voxel to get the face, edge, and corner
    # touching neighbors
    neighbors = [np.array([[-1],
                           [1]]),
                 np.array([[-1, -1],
                           [0, -1],
                           [1, -1],
                           [-1, 0],
                           [1, 0],
                           [-1, 1],
                           [0, 1],
                           [1, 1]]),
                 np.array([[-1, -1, -1],
                           [0, -1, -1],
                           [1, -1, -1],
                           [-1, 0, -1],
                           [0, 0, -1],
                           [1, 0, -1],
                           [-1, 1, -1],
                           [0, 1, -1],
                           [1, 1, -1],
                           [-1, -1, 0],
                           [0, -1, 0],
                           [1, -1, 0],
                           [-1, 0, 0],
                           [1, 0, 0],
                           [-1, 1, 0],
                           [0, 1, 0],
                           [1, 1, 0],
                           [-1, -1, 1],
                           [0, -1, 1],
                           [1, -1, 1],
                           [-1, 0, 1],
                           [0, 0, 1],
                           [1, 0, 1],
                           [-1, 1, 1],
                           [0, 1, 1],
                           [1, 1, 1]])]

    if len(msz)-1 > 3 or len(msz) < 0:
        raise ValueError("Cannot calculate neighbors for %d dimensions", len(msz)-1)

    return(np.ravel_multi_index(tuple(np.transpose(np.unravel_index(ix,msz)+neighbors[len(msz)-1])),msz))

def make_local_connectivity_ones( mask_array ):
    """

    make_local_connectivity_ones( mask_array )

    This function is a part of the ClusterROI python toolbox for the
    spatially constrained clustering of fMRI data. It constructs a spatially
    constrained connectivity matrix for a fMRI dataset. The weights w_ij of
    the connectivity matrix W are set to 1 if a voxel is within the 3D
    neighborhood (face, edge, and corner touching) of the center voxel.

    Args:
        mask_array (numpy array): 1, 2, or 3 -dimensional array with ones at
          locations that are considered "in-brain" voxels, and zero everywhere
          else

    Returns:
        edge_ndx (list of tuples): each tuple corresponds to a edge with
           (start node ndx, end node ndx, edge weight)

    :rtype: list
    """

    # type: (object) -> object

    # get the array dimensions, which will be used to calculate neighborhoods
    msz=mask_array.shape

    # reduce to two dimensions and pull out only the indices that are in the
    # brain
    mask_array=mask_array.flatten()
    ix=np.nonzero(mask_array)[0]

    print '%d non-zero voxels in the mask'%(len(ix))

    # get the range of the ix's
    ix_min = np.min(ix)
    ix_max = np.max(ix)

    mvals=[]

    # loop over all of the voxels in the mask
    for i in ix:
        seed_neigh = []
        for x in get_neighbors(i, msz):
            if ix_min <= x <= ix_max and mask_array[x] != 0:
                seed_neigh.append(x)

        mvals+=zip(int(i)*np.ones(len(seed_neigh),dtype=np.int),seed_neigh,np.ones(len(seed_neigh)))

    return(mvals)




def make_local_connectivity_tcorr(im_dat, mask_array, thresh):

    """
    This script is a part of the ClusterROI python toolbox for the spatially
    constrained clustering of fMRI data. It constructs a spatially constrained
    connectivity matrix from a fMRI dataset. The weights w_ij of the connectivity
    matrix W correspond to the _temporal_correlation_ between the time series
    from voxel i and voxel j. Connectivity is only calculated between a voxel and
    the 27 voxels in its 3D neighborhood (face touching and edge touching). The
    resulting datafiles are suitable as inputs to the function
    binfile_parcellate.

    :param infile: name of a 4D NIFTI file containing fMRI data
    :param mask_array (numpy array): 1, 2, or 3 -dimensional array with ones at
          locations that are considered "in-brain" voxels, and zero everywhere
          else
    :param thresh: Threshold value, correlation coefficients lower than this value
               will be removed from the matrix (set to zero).
    :return: edge_ndx (list of tuples): each tuple corresponds to a edge with
           (start node ndx, end node ndx, edge weight)
    """

    import sklearn.preprocessing as skp
    import warnings
    warnings.filterwarnings("ignore", category=UserWarning)

    # get the array dimensions, which will be used to calculate neighborhoods
    msz=np.shape(mask_array)

    # reduce to two dimensions and pull out only the indices that are in the
    # brain
    mask_array=mask_array.flatten()
    ix=np.nonzero(mask_array)[0]

    print '%d non-zero voxels in the mask'%(len(ix))

    # get the range of the ix's
    ix_min = np.min(ix)
    ix_max = np.max(ix)

    # conform the fmri data
    # NOTE the format of x,y,z axes and time dimension after reading
    # nb.load('x.nii.gz').shape -> (x,y,z,t)
    sz = np.shape(im_dat)
    num_tc = sz[-1]

    # reshape fmri data to a num_voxels x num_timepoints array
    im_dat = np.reshape(im_dat, (np.prod(sz[:-1]), sz[-1]))

    # standardize everything at once to make correlation calculation easier
    im_dat[ix,:] = skp.scale(im_dat[ix,:], axis=1, with_mean=True, with_std=True, copy=False)

    mvals=[]

    # loop over all of the voxels in the mask
    for i in ix:

        # extract the seed_tc and make sure it has variance, otherwise
        # we are just wasting our time
        seed_tc = im_dat[i, :]
        if seed_tc.var() == 0:
            continue

        # get all of the seeds neighbors that are in the mask
        seed_neigh = []
        for x in get_neighbors(i, msz):
            if ix_min <= x <= ix_max and mask_array[x] != 0:
                seed_neigh.append(x)

        # get the time courses for the neigbors
        neigh_tc = im_dat[seed_neigh, :]

        # calculate the correlation, and find the location of vals
        # > thresh
        R = (1.0/num_tc)*np.matmul(neigh_tc,seed_tc)

        if (R>thresh).any():
            seed_neigh = np.array(seed_neigh)
            seed_neigh = seed_neigh[R>thresh]
            R = R[R>thresh]
            mvals+=zip(int(i)*np.ones(len(seed_neigh),dtype=np.int),seed_neigh,R)

    return(mvals)

def make_local_connectivity_scorr(im_dat, mask_array, thresh):

    """
    This script is a part of the ClusterROI python toolbox for the spatially
    constrained clustering of fMRI data. It constructs a spatially constrained
    connectivity matrix from a fMRI dataset. The weights w_ij of the connectivity
    matrix W correspond to the _spatial_correlation_ between functional connectivity
    maps generated from time series from voxel i and voxel j. Connectivity is
    only calculated between a voxel and the 27 voxels in its 3D neighborhood (face
    touching and edge touching). The resulting datafiles are suitable as inputs
    to the function binfile_parcellate.

    :param infile: name of a 4D NIFTI file containing fMRI data
    :param mask_array (numpy array): 1, 2, or 3 -dimensional array with ones at
          locations that are considered "in-brain" voxels, and zero everywhere
          else
    :param thresh: Threshold value, correlation coefficients lower than this value
               will be removed from the matrix (set to zero).
    :return: edge_ndx (list of tuples): each tuple corresponds to a edge with
           (start node ndx, end node ndx, edge weight)
    """

    import sklearn.preprocessing as skp
    import warnings
    warnings.filterwarnings("ignore", category=UserWarning)

    # get the array dimensions, which will be used to calculate neighborhoods
    msz=np.shape(mask_array)

    # reduce to two dimensions and pull out only the indices that are in the
    # brain
    mask_array=mask_array.flatten()
    ix=np.nonzero(mask_array)[0]

    print '%d non-zero voxels in the mask'%(len(ix))

    # get the range of the ix's
    ix_min = np.min(ix)
    ix_max = np.max(ix)
    num_vx = len(ix)

    # conform the fmri data
    # NOTE the format of x,y,z axes and time dimension after reading
    # nb.load('x.nii.gz').shape -> (x,y,z,t)
    sz = np.shape(im_dat)
    num_tc = sz[-1]


    # reshape fmri data to a num_voxels x num_timepoints array
    im_dat = np.reshape(im_dat, (np.prod(sz[:-1]), sz[-1]))

    # standardize everything at once to make correlation calculation easier
    im_dat[ix,:] = skp.scale(im_dat[ix,:], axis=1, with_mean=True, with_std=True, copy=False)

    mvals=[]

    none_count = 0
    iter_count = 0

    # loop over all of the voxels in the mask
    for i in ix:

        # extract the seed_tc and make sure it has variance, otherwise
        # we are just wasting our time
        seed_tc = im_dat[i, :]
        if seed_tc.var() == 0:
            continue
        seed_ifc = (1.0/num_tc)*np.matmul(im_dat[ix,:],seed_tc)
        if seed_ifc.var() == 0:
            continue
        seed_ifc = skp.scale(seed_ifc, axis=0, with_mean=True, with_std=True, copy=False)

        # get all of the seeds neighbors that are in the mask
        seed_neigh = []
        for x in get_neighbors(i, msz):
            if ix_min <= x <= ix_max and mask_array[x] != 0:
                seed_neigh.append(x)

        # get the time courses for the neigbors
        neigh_tc = im_dat[seed_neigh, :]
        neigh_ifc = (1.0 / 150) * np.matmul(im_dat[ix, :], np.transpose(neigh_tc))
        if (neigh_ifc.var(0) == 0).all():
            continue
        good_ix = np.where(neigh_ifc.var(0)!=0.0)[0]
        neigh_ifc = neigh_ifc[:,good_ix]
        neigh_ifc = skp.scale(neigh_ifc, axis=0, with_mean=True, with_std=True, copy=False)

        # calculate the correlation, and find the location of vals
        # > thresh
        R = (1.0/num_vx)*(np.matmul(seed_ifc,neigh_ifc))

        if (R>thresh).any():
            seed_neigh = np.array(seed_neigh)
            seed_neigh = seed_neigh[R>thresh]
            R = R[R>thresh]
            mvals+=zip(int(i)*np.ones(len(seed_neigh),dtype=np.int),seed_neigh,R)
        else:
            none_count=none_count+1
            if none_count % 1000 == 0:
                print "%d nones encountered out of %d"%(none_count,iter_count),R
        iter_count=iter_count+1

    return(mvals)
